{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"D:\\PythonApps\\exercise_reddit_titles\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pprint\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"resources/raw_dataset.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntactical_extraction(text: str, spacy_model):\n",
    "    doc = spacy_model(text)\n",
    "    label_counts = {}\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        k = f\"ner_{ent.label_}\"\n",
    "        label_counts[k] = label_counts.get(k, 0) + 1\n",
    "    \n",
    "    for token in doc:\n",
    "        k = f\"pos_{token.pos_}\"\n",
    "        label_counts[k] = label_counts.get(k, 0) + 1\n",
    "\n",
    "    for token in doc:\n",
    "        k = f\"tag_{token.tag_}\"\n",
    "        label_counts[k] = label_counts.get(k, 0) + 1\n",
    "\n",
    "    for token in doc:\n",
    "        k = f\"lemma_{token.lemma_}\"\n",
    "        label_counts[k] = label_counts.get(k, 0) + 1\n",
    "\n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_classification(text: str, model):\n",
    "    return model(text)[0][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run functions and save records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = spacy.load(\"en_core_web_sm\")\n",
    "sentiment_model = pipeline(\"text-classification\", model=\"tabularisai/multilingual-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - Raw records\n",
    "records = []\n",
    "n = len(df)\n",
    "for i in tqdm(range(n), desc=\"Raw records\"):\n",
    "    record_id = f\"title_{i}\"\n",
    "    text = df.iloc[i][\"title\"]\n",
    "    record = dict(text=text, score=int(df.iloc[i][\"score\"]))\n",
    "    record = {\n",
    "        **record,\n",
    "        **syntactical_extraction(text, spacy_model)\n",
    "    }\n",
    "    record[\"sentiment\"] = sentiment_classification(text, sentiment_model)\n",
    "    records.append(record)\n",
    "\n",
    "\n",
    "# 1 - Unificate keys\n",
    "all_keys = []\n",
    "for r in tqdm(records, desc=\"Collecting keys\"):\n",
    "    all_keys += list(r.keys())\n",
    "\n",
    "\n",
    "# 2 - Add null keys\n",
    "for i, record in tqdm(enumerate(records), desc=\"Keys unification\"):\n",
    "    for k in all_keys:\n",
    "        records[i][k] = records[i][k] if k in records[i].keys() else 0\n",
    "\n",
    "\n",
    "json.dump(\n",
    "    records,\n",
    "    open(f\"resources/records.json\", \"w\"),\n",
    "    indent=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(records)\n",
    "base_cols = [\"text\", \"score\", \"sentiment\"]\n",
    "ner_cols = [c for c in df.columns if c.startswith(\"ner\")]\n",
    "pos_cols = [c for c in df.columns if c.startswith(\"pos\")]\n",
    "tag_cols = [c for c in df.columns if c.startswith(\"tag\")]\n",
    "lemma_cols = [c for c in df.columns if c.startswith(\"lemma\")]\n",
    "df = df[base_cols + ner_cols + pos_cols + tag_cols + lemma_cols]\n",
    "df.to_parquet(\"resources/dataframe_features.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
